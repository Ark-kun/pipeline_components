name: Train tabular classification model using PyTorch pipeline
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
    canonical_location: https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/samples/Basic_ML_training/Train_tabular_classification_model_using_PyTorch/pipeline.component.yaml
    sdk: https://cloud-pipelines.net/pipeline-editor/
implementation:
  graph:
    tasks:
      Download from GCS:
        componentRef:
          digest: 30c424ac6156c478aa0c3027b470baf9cb7dbbf90aebcabde7469bfbd02a512e
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/d8c4cf5e6403bc65bcf8d606e6baf87e2528a3dc/components/google-cloud/storage/download/component.yaml
        arguments:
          GCS path: gs://ml-pipeline-dataset/Chicago_taxi_trips/chicago_taxi_trips_2019-01-01_-_2019-02-01_limit=10000.csv
        annotations:
          editor.position: '{"x":240,"y":40,"width":180,"height":40}'
      Select columns using Pandas on CSV data:
        componentRef:
          digest: 706a611997f9354fc9380747db7265a5a18b34ae7f3deadf29c9b994042fb511
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/0f0650b8446277b10f7ab48d220e413eef04ec69/components/pandas/Select_columns/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: Data
              taskId: Download from GCS
          column_names: '["tips", "trip_seconds", "trip_miles", "pickup_community_area", "dropoff_community_area", "fare", "tolls", "extras"]'
        annotations:
          editor.position: '{"x":240,"y":140,"width":180,"height":54}'
      Fill all missing values using Pandas on CSV data:
        componentRef:
          digest: c78f49267f7bf4362e737c34251d3e2b1dda295d16891676885fe51ca67fbcc6
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/151411a5b719916b47505cd21c4541c1a5b62400/components/pandas/Fill_all_missing_values/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Select columns using Pandas on CSV data
              type: CSV
          replacement_value: '0'
        annotations:
          editor.position: '{"x":240,"y":250,"width":180,"height":54}'
      Create fully connected pytorch network:
        componentRef:
          digest: 9e9af4ec6b84b02db64bcc27caa94c992dad0cefcf72957ab1ceb651639df6bb
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/b2707e70384c710b14e787a7b868a53baf6f7b65/components/PyTorch/Create_fully_connected_network/component.yaml
        arguments:
          layer_sizes: '[7, 10, 1]'
          activation_name: elu
          output_activation_name: sigmoid
        annotations:
          editor.position: '{"x":40,"y":360,"width":180,"height":54}'
      Binarize column using Pandas on CSV data:
        componentRef:
          digest: 14f3f351dc19a36c9ef03d8399883575e2ec631830e56382ca35c13ae5b84779
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/0c7b4ea8c7048cc5cd59c161bcbfa5b742738e99/components/pandas/Binarize_column/in_CSV_format/component.yaml
        arguments:
          table:
            taskOutput:
              outputName: transformed_table
              taskId: Fill all missing values using Pandas on CSV data
              type: CSV
          column_name: tips
          predicate: ' > 0'
          new_column_name: class
        annotations:
          editor.position: '{"x":240,"y":360,"width":180,"height":54}'
      Train pytorch model from csv:
        componentRef:
          digest: 40f3185eb61e9727f41a4e0c05dd3d3b44bd802aa0f378cfc31756560033949a
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/d8c4cf5e6403bc65bcf8d606e6baf87e2528a3dc/components/PyTorch/Train_PyTorch_model/from_CSV/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: model
              taskId: Create fully connected pytorch network
              type: PyTorchScriptModule
          training_data:
            taskOutput:
              outputName: transformed_table
              taskId: Binarize column using Pandas on CSV data
              type: CSV
          label_column_name: class
          loss_function_name: binary_cross_entropy
        annotations:
          editor.position: '{"x":240,"y":490,"width":180,"height":40}'
      Convert to onnx from pytorch script module:
        componentRef:
          digest: 7edca2cd8212000a52dedf6c60aeb808fd022818ccb0ee64ddc85259b84e6186
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/d8c4cf5e6403bc65bcf8d606e6baf87e2528a3dc/components/PyTorch/Convert_to_OnnxModel_from_PyTorchScriptModule/component.yaml
        arguments:
          model:
            taskOutput:
              outputName: trained_model
              taskId: Train pytorch model from csv
              type: PyTorchScriptModule
          list_of_input_shapes: '[[7]]'
        annotations:
          editor.position: '{"x":40,"y":590,"width":180,"height":54}'
      Create PyTorch Model Archive with base handler:
        componentRef:
          digest: 8298b5ee1b0f0879f893add4cf352c8dec7cf9e21bb9db134c91a2d046cdb0ec
          url: https://raw.githubusercontent.com/Ark-kun/pipeline_components/46d51383e6554b7f3ab4fd8cf614d8c2b422fb22/components/PyTorch/Create_PyTorch_Model_Archive/with_base_handler/component.yaml
        arguments:
          Model:
            taskOutput:
              outputName: trained_model
              taskId: Train pytorch model from csv
              type: PyTorchScriptModule
          Model name: model
          Model version: '1.0'
        annotations:
          editor.position: '{"x":240,"y":590,"width":180,"height":54}'
    outputValues: {}

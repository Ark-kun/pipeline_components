name: Create dataset for google cloud automl tables
description: Creates an empty Dataset for AutoML tables
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
    canonical_location: 'https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/components/gcp/automl/create_dataset_for_tables/component.yaml'
inputs:
- {name: display_name, type: String}
- {name: description, type: String, optional: true}
- {name: tables_dataset_metadata, type: JsonObject, default: '{}', optional: true}
- {name: gcp_project_id, type: String, optional: true}
- {name: gcp_region, type: String, optional: true}
- {name: retry_config, type: JsonObject, optional: true}
- {name: timeout, type: Float, optional: true}
outputs:
- {name: dataset_name, type: String}
- {name: dataset, type: JsonObject}
- {name: dataset_path, type: String}
- {name: create_time, type: String}
- {name: dataset_id, type: String}
- {name: dataset_url, type: URI}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'google-cloud-automl==2.4.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
      install --quiet --no-warn-script-location 'google-cloud-automl==2.4.2' --user)
      && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def create_dataset_for_google_cloud_automl_tables(
          display_name,
          description = None,
          tables_dataset_metadata = {},
          gcp_project_id = None,
          gcp_region = None,
          retry_config = None, # : google.api_core.retry.Retry = google.api_core.gapic_v1.method.DEFAULT,
          timeout = None, #=google.api_core.gapic_v1.method.DEFAULT,
      ):
          '''Creates an empty Dataset for AutoML tables'''
          import logging
          import google
          from google.protobuf import json_format
          from google.cloud import automl_v1beta1 as automl
          client = automl.AutoMlClient()

          if not gcp_project_id:
              _, gcp_project_id = google.auth.default()

          if not gcp_region:
              gcp_region = 'us-central1'
          if gcp_region != 'us-central1':
              logging.warn('AutoML only supports the us-central1 region')

          dataset = client.create_dataset(
              parent=f"projects/{gcp_project_id}/locations/{gcp_region}",
              dataset=automl.Dataset(
                  display_name=display_name,
                  description=description,
                  tables_dataset_metadata=tables_dataset_metadata,
              ),
              retry=google.api_core.retry.Retry(**retry_config) if retry_config else google.api_core.gapic_v1.method.DEFAULT,
              timeout=timeout or google.api_core.gapic_v1.method.DEFAULT,
              # ! metadata was dict before, but now it's a sequence of tuples.
              #metadata=(metadata or {}).items(),
          )
          dataset_json = json_format.MessageToJson(dataset._pb)
          print(dataset_json)
          dataset_id = dataset.name.rsplit('/', 1)[-1]
          dataset_url = f'https://console.cloud.google.com/automl-tables/locations/{gcp_region}/datasets/{dataset_id}/schemav2?project={gcp_project_id}'
          print(dataset_url)
          return (dataset.name, dataset_json, dataset.name, str(dataset.create_time), dataset_id, dataset_url)

      def _serialize_json(obj) -> str:
          if isinstance(obj, str):
              return obj
          import json
          def default_serializer(obj):
              if hasattr(obj, 'to_struct'):
                  return obj.to_struct()
              else:
                  raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
          return json.dumps(obj, default=default_serializer, sort_keys=True)

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
          return str_value

      import json
      import argparse
      _parser = argparse.ArgumentParser(prog='Create dataset for google cloud automl tables', description='Creates an empty Dataset for AutoML tables')
      _parser.add_argument("--display-name", dest="display_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--description", dest="description", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--tables-dataset-metadata", dest="tables_dataset_metadata", type=json.loads, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--gcp-project-id", dest="gcp_project_id", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--gcp-region", dest="gcp_region", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--retry-config", dest="retry_config", type=json.loads, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--timeout", dest="timeout", type=float, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=6)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = create_dataset_for_google_cloud_automl_tables(**_parsed_args)

      _output_serializers = [
          _serialize_str,
          _serialize_json,
          _serialize_str,
          _serialize_str,
          _serialize_str,
          str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --display-name
    - {inputValue: display_name}
    - if:
        cond: {isPresent: description}
        then:
        - --description
        - {inputValue: description}
    - if:
        cond: {isPresent: tables_dataset_metadata}
        then:
        - --tables-dataset-metadata
        - {inputValue: tables_dataset_metadata}
    - if:
        cond: {isPresent: gcp_project_id}
        then:
        - --gcp-project-id
        - {inputValue: gcp_project_id}
    - if:
        cond: {isPresent: gcp_region}
        then:
        - --gcp-region
        - {inputValue: gcp_region}
    - if:
        cond: {isPresent: retry_config}
        then:
        - --retry-config
        - {inputValue: retry_config}
    - if:
        cond: {isPresent: timeout}
        then:
        - --timeout
        - {inputValue: timeout}
    - '----output-paths'
    - {outputPath: dataset_name}
    - {outputPath: dataset}
    - {outputPath: dataset_path}
    - {outputPath: create_time}
    - {outputPath: dataset_id}
    - {outputPath: dataset_url}

name: Train logistic regression model using scikit learn from CSV
description: Trains logistic regression model using Scikit-learn.
metadata:
  annotations: {author: Alexey Volkov <alexey.volkov@ark-kun.com>, canonical_location: 'https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/components/ML_frameworks/Scikit_learn/Train_logistic_regression_model/from_CSV/component.yaml'}
inputs:
- {name: dataset, type: CSV, description: Tabular dataset for training.}
- {name: label_column_name, type: String, description: Name of the data column to
    use as label.}
- name: penalty
  type: String
  description: |-
    Used to specify the norm used in the penalization.
    Possible values: {'l1', 'l2', 'elasticnet', 'none'}, default='l2'
    The 'newton-cg',
    'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
    only supported by the 'saga' solver. If 'none' (not supported by the
    liblinear solver), no regularization is applied.
  default: l2
  optional: true
- name: solver
  type: String
  description: |-
    Algorithm to use in the optimization problem.
    Possible values: {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default='lbfgs'

    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and
    'saga' are faster for large ones.
    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
    handle multinomial loss; 'liblinear' is limited to one-versus-rest
    schemes.
    - 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty
    - 'liblinear' and 'saga' also handle L1 penalty
    - 'saga' also supports 'elasticnet' penalty
    - 'liblinear' does not support setting ``penalty='none'``

    Note that 'sag' and 'saga' fast convergence is only guaranteed on
    features with approximately the same scale. You can
    preprocess the data with a scaler from sklearn.preprocessing.
  default: lbfgs
  optional: true
- {name: max_iterations, type: Integer, description: Maximum number of iterations
    taken for the solvers to converge., default: '100', optional: true}
- name: multi_class_mode
  type: String
  description: |-
    Possible values: {'auto', 'ovr', 'multinomial'}, default='auto'
    If the option chosen is 'ovr', then a binary problem is fit for each
    label. For 'multinomial' the loss minimised is the multinomial loss fit
    across the entire probability distribution, *even when the data is
    binary*. 'multinomial' is unavailable when solver='liblinear'.
    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
    and otherwise selects 'multinomial'.
  default: auto
  optional: true
- {name: random_seed, type: Integer, description: Controls the seed of the random
    processes., default: '0', optional: true}
outputs:
- {name: model, type: ScikitLearnPickleModel, description: Trained model in Scikit-learn
    pickle format.}
- {name: model_parameters, type: JsonObject}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn==1.0.2' 'pandas==1.4.3' 'numpy<2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
      -m pip install --quiet --no-warn-script-location 'scikit-learn==1.0.2' 'pandas==1.4.3' 'numpy<2'
      --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def train_logistic_regression_model_using_scikit_learn_from_CSV(
          dataset_path,
          model_path,
          label_column_name,
          penalty = "l2", # l1, l2, elasticnet, none
          solver = "lbfgs", # newton-cg, lbfgs, liblinear, sag, saga
          max_iterations = 100,
          multi_class_mode = "auto", # auto, ovr, multinomial
          random_seed = 0,
      ):
          """Trains logistic regression model using Scikit-learn.

          See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

          Args:
              dataset_path: Tabular dataset for training.
              model_path: Trained model in Scikit-learn pickle format.
              label_column_name: Name of the data column to use as label.
              penalty: Used to specify the norm used in the penalization.
                  Possible values: {'l1', 'l2', 'elasticnet', 'none'}, default='l2'
                  The 'newton-cg',
                  'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
                  only supported by the 'saga' solver. If 'none' (not supported by the
                  liblinear solver), no regularization is applied.
              solver: Algorithm to use in the optimization problem.
                  Possible values: {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default='lbfgs'

                  - For small datasets, 'liblinear' is a good choice, whereas 'sag' and
                  'saga' are faster for large ones.
                  - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'
                  handle multinomial loss; 'liblinear' is limited to one-versus-rest
                  schemes.
                  - 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty
                  - 'liblinear' and 'saga' also handle L1 penalty
                  - 'saga' also supports 'elasticnet' penalty
                  - 'liblinear' does not support setting ``penalty='none'``

                  Note that 'sag' and 'saga' fast convergence is only guaranteed on
                  features with approximately the same scale. You can
                  preprocess the data with a scaler from sklearn.preprocessing.
              max_iterations: Maximum number of iterations taken for the solvers to converge.
              multi_class_mode: Possible values: {'auto', 'ovr', 'multinomial'}, default='auto'
                  If the option chosen is 'ovr', then a binary problem is fit for each
                  label. For 'multinomial' the loss minimised is the multinomial loss fit
                  across the entire probability distribution, *even when the data is
                  binary*. 'multinomial' is unavailable when solver='liblinear'.
                  'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
                  and otherwise selects 'multinomial'.
              random_seed: Controls the seed of the random processes.
          """
          import json
          import pandas
          import pickle
          from sklearn import linear_model

          df = pandas.read_csv(dataset_path)
          model = linear_model.LogisticRegression(
              penalty=penalty,
              #dual=False,
              #tol=1e-4,
              #C=1.0,
              #fit_intercept=True,
              #intercept_scaling=1,
              #class_weight=None,
              random_state=random_seed,
              solver=solver,
              max_iter=max_iterations,
              multi_class=multi_class_mode,
              #l1_ratio=None,
              verbose=1,
          )

          model_parameters = model.get_params()
          model_parameters_json = json.dumps(model_parameters, indent=2)
          print("Model parameters:")
          print(model_parameters_json)
          print()

          model.fit(
              X=df.drop(columns=label_column_name),
              y=df[label_column_name],
          )

          with open(model_path, "wb") as f:
              pickle.dump(model, f)

          return (model_parameters_json,)

      def _serialize_json(obj) -> str:
          if isinstance(obj, str):
              return obj
          import json
          def default_serializer(obj):
              if hasattr(obj, 'to_struct'):
                  return obj.to_struct()
              else:
                  raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
          return json.dumps(obj, default=default_serializer, sort_keys=True)

      import argparse
      _parser = argparse.ArgumentParser(prog='Train logistic regression model using scikit learn from CSV', description='Trains logistic regression model using Scikit-learn.')
      _parser.add_argument("--dataset", dest="dataset_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--label-column-name", dest="label_column_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--penalty", dest="penalty", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--solver", dest="solver", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--max-iterations", dest="max_iterations", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--multi-class-mode", dest="multi_class_mode", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--random-seed", dest="random_seed", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = train_logistic_regression_model_using_scikit_learn_from_CSV(**_parsed_args)

      _output_serializers = [
          _serialize_json,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --dataset
    - {inputPath: dataset}
    - --label-column-name
    - {inputValue: label_column_name}
    - if:
        cond: {isPresent: penalty}
        then:
        - --penalty
        - {inputValue: penalty}
    - if:
        cond: {isPresent: solver}
        then:
        - --solver
        - {inputValue: solver}
    - if:
        cond: {isPresent: max_iterations}
        then:
        - --max-iterations
        - {inputValue: max_iterations}
    - if:
        cond: {isPresent: multi_class_mode}
        then:
        - --multi-class-mode
        - {inputValue: multi_class_mode}
    - if:
        cond: {isPresent: random_seed}
        then:
        - --random-seed
        - {inputValue: random_seed}
    - --model
    - {outputPath: model}
    - '----output-paths'
    - {outputPath: model_parameters}
